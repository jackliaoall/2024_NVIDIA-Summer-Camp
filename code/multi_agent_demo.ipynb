{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 NIM 建构多模态 AI-Agent (代码 demo+练习)\n",
    "\n",
    "本次课程将着重介绍一下内容:\n",
    "\n",
    "* 多模态模型基于 NIM 的调用方式\n",
    "* 基于 NIM 接口实现 Phi-3-Vision 的推理实践\n",
    "* 基于 Gradio 框架建立前端互动界面\n",
    "\n",
    "## 申请NIM的API Key，来调用NIM的计算资源\n",
    "\n",
    "进入[https://build.nvidia.com/microsoft/phi-3-vision-128k-instruct](https://build.nvidia.com/microsoft/phi-3-vision-128k-instruct), 点击**Get API Key**按钮，生成一个秘钥\n",
    "\n",
    "![](https://v.png.pub/imgs/2024/07/01/72fa333bb5bee55b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步, 导入工具包\n",
    "\n",
    "本次实验主要需要三个工具包:\n",
    "\n",
    "* `langchain_nvidia_ai_endpoint`: 用来调用nvidia nim的计算资源\n",
    "* `langchain`: 用来构建对话链, 将智能体的各个组件串联起来\n",
    "* `base64`: 因为本实验是构建多模态的智能体, 需要base64来对图像进行编解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    " \n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将上面准备好的秘钥粘贴在此处, 当我们向服务器发送计算请求时, 需要用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NVIDIA_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看当前可以使用的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatNVIDIA.get_available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步, 利用Microsoft Phi 3 vision 来解析图片数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将图片进行编解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2b64(image_file):\n",
    "    with open(image_file, \"rb\") as f:\n",
    "        image_b64 = base64.b64encode(f.read()).decode()\n",
    "        return image_b64\n",
    "\n",
    "image_b64 = image2b64(\"economic-assistance-chart.png\")\n",
    "# image_b64 = image2b64(\"eco-good-bad-chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "display(Image.open(\"economic-assistance-chart.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将编码后的图像按照格式给到Microsoft Phi 3 vision , 利用其强大能力解析图片中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_reading = ChatNVIDIA(model=\"ai-phi-3-vision-128k-instruct\")\n",
    "result = chart_reading.invoke(f'Generate underlying data table of the figure below, : <img src=\"data:image/png;base64,{image_b64}\" />')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "当然您也可以调用任何其他大模型来为您工作\n",
    "\n",
    "下面的示例中, 调用Llama3 70b的模型,通过中文输入提示词,来进行工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_chat = ChatNVIDIA(model=\"ai-llama3-70b\")\n",
    "# result = instruct_chat.invoke('How to implement Fibonacci in python using dynamic programming')\n",
    "result = instruct_chat.invoke('怎么用 Python 实现快速排序')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三步, 使用 LangChain 构建多模态智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agent 应用场景**：将图片中的统计图表转换为可以用 python 进行分析的数据\n",
    "\n",
    "**Agent 工作流**：\n",
    "- 接收图片，读取图片数据\n",
    "- 对数据进行调整、分析\n",
    "- 生成能够绘制图片的代码,并执行代码\n",
    "- 根据处理后的数据绘制图表\n",
    "\n",
    "**接收图片 -> 分析数据 -> 修改数据 -> 生成绘制图片的代码 -> 执行代码 -> 展示结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 辅助函数\n",
    "\n",
    "这里的函数用于显示输入, 执行代码等, 在我们执行过程中可能会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 将 langchain 运行状态下的表保存到全局变量中\n",
    "def save_table_to_global(x):\n",
    "    global table\n",
    "    if 'TABLE' in x.content:\n",
    "        table = x.content.split('TABLE', 1)[1].split('END_TABLE')[0]\n",
    "    return x\n",
    "\n",
    "# helper function 用于Debug\n",
    "def print_and_return(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "# 对打模型生成的代码进行处理, 将注释或解释性文字去除掉, 留下pyhon代码\n",
    "def extract_python_code(text):\n",
    "    pattern = r'```python\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return [match.strip() for match in matches]\n",
    "\n",
    "# 执行由大模型生成的代码\n",
    "def execute_and_return(x):\n",
    "    code = extract_python_code(x.content)[0]\n",
    "    try:\n",
    "        result = exec(str(code))\n",
    "        #print(\"exec result: \"+result)\n",
    "    except ExceptionType:\n",
    "        print(\"The code is not executable, don't give up, try again!\")\n",
    "    return x\n",
    "\n",
    "# 将图片编码成base64格式, 以方便输入给大模型\n",
    "def image2b64(image_file):\n",
    "    with open(image_file, \"rb\") as f:\n",
    "        image_b64 = base64.b64encode(f.read()).decode()\n",
    "        return image_b64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义多模态数据分析 Agent\n",
    "\n",
    "* 这里首先定义了提示词模板, chart_reading_prompt, 我们输入的图片会边恒base64格式的string传输给它\n",
    "* 将处理好的提示词输入给char_reading, 也就是microsoft/phi-3-vision大模型来进行数据分析, 得到我们需要的表格或者说table变量\n",
    "* 将Phi3 vision处理好的table和提示词输入给另一个大模型llama3.1, 修改数据并生成代码\n",
    "* 将生成的代码通过上面的执行函数来执行python代码, 并得到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_agent(image_b64, user_input, table):\n",
    "    # Chart reading Runnable\n",
    "    chart_reading = ChatNVIDIA(model=\"ai-phi-3-vision-128k-instruct\")\n",
    "    chart_reading_prompt = ChatPromptTemplate.from_template(\n",
    "        'Generate underlying data table of the figure below, : <img src=\"data:image/png;base64,{image_b64}\" />'\n",
    "    )\n",
    "    chart_chain = chart_reading_prompt | chart_reading\n",
    "\n",
    "    # Instruct LLM Runnable\n",
    "    # instruct_chat = ChatNVIDIA(model=\"nv-mistralai/mistral-nemo-12b-instruct\")\n",
    "    # instruct_chat = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "    #instruct_chat = ChatNVIDIA(model=\"ai-llama3-70b\")\n",
    "    instruct_chat = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
    "\n",
    "    instruct_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Do NOT repeat my requirements already stated. Based on this table {table}, {input}\" \\\n",
    "        \"If has table string, start with 'TABLE', end with 'END_TABLE'.\" \\\n",
    "        \"If has code, start with '```python' and end with '```'.\" \\\n",
    "        \"Do NOT include table inside code, and vice versa.\"\n",
    "    )\n",
    "    instruct_chain = instruct_prompt | instruct_chat\n",
    "\n",
    "    # 根据“表格”决定是否读取图表\n",
    "    chart_reading_branch = RunnableBranch(\n",
    "        (lambda x: x.get('table') is None, RunnableAssign({'table': chart_chain })),\n",
    "        (lambda x: x.get('table') is not None, lambda x: x),\n",
    "        lambda x: x\n",
    "    )\n",
    "    # 根据需求更新table\n",
    "    update_table = RunnableBranch(\n",
    "        (lambda x: 'TABLE' in x.content, save_table_to_global),\n",
    "        lambda x: x\n",
    "    )\n",
    "    # 执行绘制图表的代码\n",
    "    execute_code = RunnableBranch(\n",
    "        (lambda x: '```python' in x.content, execute_and_return),\n",
    "        lambda x: x\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        chart_reading_branch\n",
    "        #| RunnableLambda(print_and_return)\n",
    "        | instruct_chain\n",
    "        #| RunnableLambda(print_and_return)\n",
    "        | update_table\n",
    "        | execute_code\n",
    "    )\n",
    "\n",
    "    return chain.invoke({\"image_b64\": image_b64, \"input\": user_input, \"table\": table}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用全局变量 table 来存储数据\n",
    "table = None\n",
    "# 将要处理的图像转换成base64格式\n",
    "image_b64 = image2b64(\"economic-assistance-chart.png\")\n",
    "\n",
    "#展示读取的图片\n",
    "from PIL import Image\n",
    "\n",
    "display(Image.open(\"economic-assistance-chart.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行上面构建好的智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先将图片的数据转为字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"show this table in string\"\n",
    "chart_agent(image_b64, user_input, table)\n",
    "print(table)    # let's see what 'table' looks like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 让 Agent 自己尝试修改其中的内容\n",
    "\n",
    "比如我们这里要把所有的UK 替换成United Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"replace table string's 'UK' with 'United Kingdom'\"\n",
    "chart_agent(image_b64, user_input, table)\n",
    "print(table)    # let's see what 'table' looks like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用 python 绘制图表\n",
    "\n",
    "这里会让大模型生成绘制图像的代码, 并执行生成的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"draw this table as stacked bar chart in python\"\n",
    "result = chart_agent(image_b64, user_input, table)\n",
    "print(\"result: \"+result)  # let's see what 'table' looks like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步, 将多模态智能体封装进Gradio\n",
    "\n",
    "当我们完成上述任务的时候, 就拥有了一个可以分析图片, 生成代码, 修改数据, 执行代码的智能体\n",
    "\n",
    "接下来我们给这个智能体添加一个UI界面, 让我们可以更舒服的与之对话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们修改一下执行代码的函数, 因为原生的Python中exec函数的返回是Nan, 所以我们给他添加一个生成图片的路径\n",
    "\n",
    "在下面的代码中, 路径是作者的PC中的路径, 请您根据您自己的系统更换这个文件夹路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global img_path\n",
    "img_path = '/home/nvidia/2024_summer_bootcamp/day3/'+'image.png'\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_and_return_gr(x):\n",
    "    code = extract_python_code(x.content)[0]\n",
    "    try:\n",
    "        result = exec(str(code))\n",
    "        #print(\"exec result: \"+result)\n",
    "    except ExceptionType:\n",
    "        print(\"The code is not executable, don't give up, try again!\")\n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个chart_agent函数的输入原来是base64格式, 但是gradio中上传图片的格式是png或jpg等图片格式\n",
    "\n",
    "所以我们更新了这个函数, 在最开始的步骤中加入了一个编码的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_agent_gr(image_b64, user_input, table):\n",
    "\n",
    "    image_b64 = image2b64(image_b64)\n",
    "    # Chart reading Runnable\n",
    "    chart_reading = ChatNVIDIA(model=\"microsoft/phi-3-vision-128k-instruct\")\n",
    "    chart_reading_prompt = ChatPromptTemplate.from_template(\n",
    "        'Generate underlying data table of the figure below, : <img src=\"data:image/png;base64,{image_b64}\" />'\n",
    "    )\n",
    "    chart_chain = chart_reading_prompt | chart_reading\n",
    "\n",
    "    # Instruct LLM Runnable\n",
    "    # instruct_chat = ChatNVIDIA(model=\"nv-mistralai/mistral-nemo-12b-instruct\")\n",
    "    # instruct_chat = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "    #instruct_chat = ChatNVIDIA(model=\"ai-llama3-70b\")\n",
    "    instruct_chat = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
    "\n",
    "    instruct_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Do NOT repeat my requirements already stated. Based on this table {table}, {input}\" \\\n",
    "        \"If has table string, start with 'TABLE', end with 'END_TABLE'.\" \\\n",
    "        \"If has code, start with '```python' and end with '```'.\" \\\n",
    "        \"Do NOT include table inside code, and vice versa.\"\n",
    "    )\n",
    "    instruct_chain = instruct_prompt | instruct_chat\n",
    "\n",
    "    # 根据“表格”决定是否读取图表\n",
    "    chart_reading_branch = RunnableBranch(\n",
    "        (lambda x: x.get('table') is None, RunnableAssign({'table': chart_chain })),\n",
    "        (lambda x: x.get('table') is not None, lambda x: x),\n",
    "        lambda x: x\n",
    "    )\n",
    "    \n",
    "    # 根据需求更新table\n",
    "    update_table = RunnableBranch(\n",
    "        (lambda x: 'TABLE' in x.content, save_table_to_global),\n",
    "        lambda x: x\n",
    "    )\n",
    "\n",
    "    execute_code = RunnableBranch(\n",
    "        (lambda x: '```python' in x.content, execute_and_return_gr),\n",
    "        lambda x: x\n",
    "    )\n",
    "    \n",
    "    # 执行绘制图表的代码\n",
    "    chain = (\n",
    "        chart_reading_branch\n",
    "        | RunnableLambda(print_and_return)\n",
    "        | instruct_chain\n",
    "        | RunnableLambda(print_and_return)\n",
    "        | update_table\n",
    "        | execute_code\n",
    "    )\n",
    "\n",
    "    return chain.invoke({\"image_b64\": image_b64, \"input\": user_input, \"table\": table})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是示意提示词, 放大家打开Gradio页面时候直接复制粘贴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"replace table string's 'UK' with 'United Kingdom', draw this table as stacked bar chart in python, and save the image in path: \"+img_path\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行上述代码, 将打开一个Gradio的服务, 我们可以利用Gradio的页面与构建好的智能体对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "multi_modal_chart_agent = gr.Interface(fn=chart_agent_gr,\n",
    "                    inputs=[gr.Image(label=\"Upload image\", type=\"filepath\"), 'text'],\n",
    "                    outputs=['image'],\n",
    "                    title=\"Multi Modal chat agent\",\n",
    "                    description=\"Multi Modal chat agent\",\n",
    "                    allow_flagging=\"never\")\n",
    "\n",
    "multi_modal_chart_agent.launch(debug=True, share=False, show_api=False, server_port=5000, server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
